{"componentChunkName":"component---src-templates-blog-js","path":"/blog/data-tools","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Data Analysis Tool Shootout","description":"In Excel, Python and R","date":"2021-02-14"},"html":"<p>Let's perform a mini data analysis tool shoot-out, specifically to perform multiple regression. Excel vs Python vs R.</p>\n<p>Truth be told, I've just started on my R journey (I've used both Excel and Python for quite some time), and I thought it would be interesting to do a simple exercise were I could use all the tools at my disposal on the same data set. </p>\n<p>Here's a quick summary of the dataset of college basketball teams' performance in the United States across four years from <a href=\"https://www.kaggle.com/andrewsundberg/college-basketball-dataset\">kaggle</a>, and the variables we will concern ourselves with. Let's pretend we are modeling the factors on the court that relate to a team's winning percentage.</p>\n<pre><code>Dependent variable:\nW_PER - Percentage of games won out of all games played\n\nIndependent variables:\nADJOE - Adjusted Offensive Efficiency (An estimate of the offensive efficiency (points scored per 100 possessions) a team\nADJDE - Adjusted Defensive Efficiency (An estimate of the defensive efficiency (points allowed per 100 possessions) a team\nEFG_O - Effective Field Goal Percentage Shot\nEFG_D - Effective Field Goal Percentage Allowed\n</code></pre>\n<p>I won't go into the analysis of the results, as this is a quick survey of the tools themselves.</p>\n<h2>Excel</h2>\n<p>Let's start with Excel. No code here, so here's what I did.</p>\n<ol>\n<li>Open the csv file in Microsoft Excel.</li>\n<li>Chose <code>Data Analysis</code> under the <code>Data</code> tab, then selected <code>Regression</code> from the options provided.</li>\n<li>Selected the cell ranges for both the dependent and independent columns.</li>\n<li>Voila!</li>\n</ol>\n<pre><code>SUMMARY OUTPUT                              \n                                \nRegression Statistics                               \nMultiple R        0.843510087                           \nR Square          0.711509267                           \nAdjusted R Square   0.710850612                         \nStandard Error    0.095941213                           \nObservations        1757                            \n                                \nANOVA                               \ndf  SS  MS  F   Significance F          \nRegression  4   39.77344423 9.943361058 1080.246341 0           \nResidual    1752    16.12666289 0.009204716                 \nTotal   1756    55.90010712                     \n                                \nCoefficients    Standard Error  t Stat  P-value Lower 95%   Upper 95%   Lower 95.0% Upper 95.0%\nIntercept   0.37890688  0.071737092 5.281882329 1.43832E-07 0.238207562 0.519606198 0.238207562 0.519606198\nADJOE   0.005448706 0.000558075 9.763384869 5.80165E-22 0.004354142 0.00654327  0.004354142 0.00654327\nADJDE   -0.005628197    0.000669195 -8.410396349    8.35282E-17 -0.006940702    -0.004315692    -0.006940702    -0.004315692\nEFG_O   0.022003087 0.001123034 19.5925424  1.90733E-77 0.01980046  0.024205715 0.01980046  0.024205715\nEFG_D   -0.018833761    0.001331731 -14.14231828    4.43852E-43 -0.02144571 -0.016221812    -0.02144571 -0.016221812\n</code></pre>\n<p>Ol' reliable Excel never fails. This is a small data set, we'll need more heavy-duty tools once our records go into the tens of thousands. On to python.</p>\n<h2>Python</h2>\n<p>Let's import the packages we need, just the usual suspects.</p>\n<pre><code class=\"language-python\">import pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\nsns.set()\n</code></pre>\n<p>Then, we grab our data from the csv file, and look at the data.</p>\n<pre><code class=\"language-python\">data = pd.read_csv('cbb.csv')\ndata\n</code></pre>\n<p>Now, we perform the regression itself.</p>\n<pre><code class=\"language-python\">y = data['W_PER']\ndata[['ADJOE', 'ADJDE', 'EFG_O', 'EFG_D']]\n\nx = sm.add_constant(x1)\nresults = sm.OLS(y,x).fit()\n\nresults.summary()\n</code></pre>\n<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>          <td>W_PER</td>      <th>  R-squared:         </th> <td>   0.712</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.711</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1080.</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sun, 14 Feb 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n</tr>\n<tr>\n  <th>Time:</th>                 <td>18:34:06</td>     <th>  Log-Likelihood:    </th> <td>  1627.9</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>  1757</td>      <th>  AIC:               </th> <td>  -3246.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>  1752</td>      <th>  BIC:               </th> <td>  -3218.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td>    0.3789</td> <td>    0.072</td> <td>    5.282</td> <td> 0.000</td> <td>    0.238</td> <td>    0.520</td>\n</tr>\n<tr>\n  <th>ADJOE</th> <td>    0.0054</td> <td>    0.001</td> <td>    9.763</td> <td> 0.000</td> <td>    0.004</td> <td>    0.007</td>\n</tr>\n<tr>\n  <th>ADJDE</th> <td>   -0.0056</td> <td>    0.001</td> <td>   -8.410</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.004</td>\n</tr>\n<tr>\n  <th>EFG_O</th> <td>    0.0220</td> <td>    0.001</td> <td>   19.593</td> <td> 0.000</td> <td>    0.020</td> <td>    0.024</td>\n</tr>\n<tr>\n  <th>EFG_D</th> <td>   -0.0188</td> <td>    0.001</td> <td>  -14.142</td> <td> 0.000</td> <td>   -0.021</td> <td>   -0.016</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 6.712</td> <th>  Durbin-Watson:     </th> <td>   1.575</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.035</td> <th>  Jarque-Bera (JB):  </th> <td>   6.796</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.148</td> <th>  Prob(JB):          </th> <td>  0.0334</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.929</td> <th>  Cond. No.          </th> <td>5.10e+03</td>\n</tr>\n</table>\n<p>Just a couple lines of code, but I get the same result as previously in Excel.</p>\n<h2>R</h2>\n<p>(Hope it's nothing like other languages named just one letter. Like C.)</p>\n<p>Once again, we grab the data.</p>\n<pre><code>cbb.data &#x3C;- read.csv('cbb.csv', fileEncoding=\"UTF-8-BOM\")\n</code></pre>\n<p>We define our dependant and independent variables, and fetch our summary.</p>\n<pre><code>multiple.regression &#x3C;- lm(W_PER ~ ADJOE + EFG_O + TOR + ORB, data=cbb.data)\n\nsummary(multiple.regression)\n</code></pre>\n<p>And the result:</p>\n<pre><code>Residuals:\n     Min       1Q   Median       3Q      Max \n-0.27208 -0.06637 -0.00104  0.06112  0.33404 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.3789069  0.0717371   5.282 1.44e-07 ***\nADJOE        0.0054487  0.0005581   9.763  &#x3C; 2e-16 ***\nADJDE       -0.0056282  0.0006692  -8.410  &#x3C; 2e-16 ***\nEFG_O        0.0220031  0.0011230  19.593  &#x3C; 2e-16 ***\nEFG_D       -0.0188338  0.0013317 -14.142  &#x3C; 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.09594 on 1752 degrees of freedom\nMultiple R-squared:  0.7115,    Adjusted R-squared:  0.7109 \nF-statistic:  1080 on 4 and 1752 DF,  p-value: &#x3C; 2.2e-16\n</code></pre>\n<p>As a beginner to R, I must say, the language feels clean and there seems to be more given out of the box as compared to python. I'll have to dig into this, as I could be wrong.</p>\n<h2>Final Thoughts</h2>\n<p>My first thoughts when cracking open RStudio was that, man, this feels like it came from the past, a different age. And the funky <code>&#x3C;-</code> variable assignment syntax looked really strange at the start.</p>\n<p>But, I can see why many data science practitioners prefer the R ecosystem. It's mature, with robust standard libraries, and it gets the job done. I'm excited to dive deeper already.</p>\n<p>This tiny exercise also reaffirms my sense that it really is not the tool, but the wielder that matters when it comes to performing data analysis.</p>\n<p>I might do some actual analysis on this dataset eventually, but till then! </p>"}},"pageContext":{"slug":"data-tools"}},"staticQueryHashes":["3159585216","3159585216","440568431"]}